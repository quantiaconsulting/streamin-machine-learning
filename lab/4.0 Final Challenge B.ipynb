{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extending functionality - Solution\n",
    "\n",
    "## Implement a simple estimator\n",
    "\n",
    "\n",
    "A core design element in `river` is that it should be easy to create new methods or extend existing methods.\n",
    "\n",
    "In the following example, we show how to implement the `MajorityClassClassifier`.\n",
    "\n",
    "The Majority Class is one of the simplest classifiers: it predicts the class of a new sample to be the most frequent at that point in the stream.\n",
    "\n",
    "It is used mostly as a baseline, but also as a default classifier at the leaves of decision trees.\n",
    "\n",
    "`River` provides a set of `mixins` for different learning tasks. In this case, we want to create a classifier so we extend the `base.Classifier` mixin as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import base\n",
    "from collections import Counter\n",
    "\n",
    "class MajorityClassClassifier(base.Classifier):\n",
    "    def __init__(self):\n",
    "        # Initialization\n",
    "        self._counts = Counter()\n",
    "    \n",
    "    def learn_one(self, x:dict, y):\n",
    "        # Learn one sample\n",
    "        self._counts.update([y])\n",
    "\n",
    "    def predict_one(self, x:dict):\n",
    "        # Predict class for one sample\n",
    "        mc = self._counts.most_common()\n",
    "        if mc:\n",
    "            return mc[0][0]\n",
    "        return 0   # Counter is empty\n",
    "\n",
    "    def predict_proba_one(self, x:dict):\n",
    "        # Predict class probability for one sample\n",
    "        total = sum(self._counts)\n",
    "        y_proba = {}\n",
    "        if total > 0:    # Protect division by zero\n",
    "            for x, cnt in self._counts.items():\n",
    "                y_proba[x] = cnt / total\n",
    "        return y_proba\n",
    "    \n",
    "    @property\n",
    "    def _multiclass(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEA Stream\n",
    "---\n",
    "Each observation in [SEA](https://riverml.xyz/latest/api/synth/SEA/) generator is composed of 3 features. Only the first two features are relevant. The target is binary, and is positive if the sum of the features exceeds a certain threshold.\n",
    "\n",
    "Synthetic data generators are useful since they do not store the data but generate it on demand. Although data generators are infinite, for this example, we limit the number of samples generated using the `take()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import synth\n",
    "\n",
    "stream = synth.SEA(seed=42).take(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,000] Accuracy: 69.70%\n",
      "[2,000] Accuracy: 69.30%\n",
      "[3,000] Accuracy: 69.23%\n",
      "[4,000] Accuracy: 69.17%\n",
      "[5,000] Accuracy: 69.12%\n",
      "[6,000] Accuracy: 68.80%\n",
      "[7,000] Accuracy: 68.61%\n",
      "[8,000] Accuracy: 68.45%\n",
      "[9,000] Accuracy: 68.47%\n",
      "[10,000] Accuracy: 68.34%\n",
      "[11,000] Accuracy: 68.37%\n",
      "[12,000] Accuracy: 68.30%\n",
      "[13,000] Accuracy: 68.32%\n",
      "[14,000] Accuracy: 68.32%\n",
      "[15,000] Accuracy: 68.27%\n",
      "[16,000] Accuracy: 68.34%\n",
      "[17,000] Accuracy: 68.34%\n",
      "[18,000] Accuracy: 68.21%\n",
      "[19,000] Accuracy: 68.18%\n",
      "[20,000] Accuracy: 68.20%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 68.20%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river.metrics import Accuracy\n",
    "from river.evaluate import progressive_val_score\n",
    "\n",
    "model = MajorityClassClassifier()\n",
    "metric = Accuracy()\n",
    "\n",
    "progressive_val_score(dataset=stream, model=model, metric=metric, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is consistent with the class distribution as the data is slightly unbalanced in favor of the `True` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6821"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._counts[True] / sum(model._counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, the performance of simple methods such as the majority class classifier is as a baseline.\n",
    "\n",
    "For example, we can compare it against the Gaussian Naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,000] Accuracy: 92.99%\n",
      "[2,000] Accuracy: 93.70%\n",
      "[3,000] Accuracy: 94.23%\n",
      "[4,000] Accuracy: 94.37%\n",
      "[5,000] Accuracy: 94.40%\n",
      "[6,000] Accuracy: 94.05%\n",
      "[7,000] Accuracy: 94.00%\n",
      "[8,000] Accuracy: 93.96%\n",
      "[9,000] Accuracy: 94.02%\n",
      "[10,000] Accuracy: 94.03%\n",
      "[11,000] Accuracy: 94.16%\n",
      "[12,000] Accuracy: 94.27%\n",
      "[13,000] Accuracy: 94.25%\n",
      "[14,000] Accuracy: 94.23%\n",
      "[15,000] Accuracy: 94.14%\n",
      "[16,000] Accuracy: 94.16%\n",
      "[17,000] Accuracy: 94.10%\n",
      "[18,000] Accuracy: 94.08%\n",
      "[19,000] Accuracy: 94.08%\n",
      "[20,000] Accuracy: 94.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 94.11%"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river.naive_bayes import GaussianNB\n",
    "\n",
    "stream = synth.SEA(seed=42).take(20000)\n",
    "\n",
    "model = GaussianNB()\n",
    "metric = Accuracy()\n",
    "\n",
    "progressive_val_score(dataset=stream, model=model, metric=metric, print_every=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Change Classifier\n",
    "\n",
    "---\n",
    "Implement the `NoChangeClassifier`, which predicts the label for a new instance to be the true label of the previous instance. Like the Majority Class classifier, it does not require the instance features, so it is very easy to implement. In the intrusion detection case where long passages of “no intrusion” are followed with briefer periods of “intrusion,” this classifier makes mistakes only on the boundary cases, adjusting quickly to the consistent pattern of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import base\n",
    "\n",
    "class NoChangeClassifier(base.Classifier):\n",
    "    def __init__(self):\n",
    "        # Initialization\n",
    "        self._last_y = 0\n",
    "        self._classes = []\n",
    "    \n",
    "    def learn_one(self, x:dict, y):\n",
    "        # Learn one sample\n",
    "        <FILL-IN>\n",
    "\n",
    "    def predict_one(self, x:dict):\n",
    "        # Predict class for one sample        \n",
    "        <FILL-IN>\n",
    "\n",
    "    def predict_proba_one(self, x:dict):\n",
    "        # Predict class probability for one sample        \n",
    "        y_proba = {}        \n",
    "        <FILL-IN>\n",
    "        return y_proba\n",
    "    \n",
    "    @property\n",
    "    def _multiclass(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,000] Accuracy: 58.40%\n",
      "[2,000] Accuracy: 57.80%\n",
      "[3,000] Accuracy: 57.87%\n",
      "[4,000] Accuracy: 57.53%\n",
      "[5,000] Accuracy: 57.14%\n",
      "[6,000] Accuracy: 57.08%\n",
      "[7,000] Accuracy: 56.67%\n",
      "[8,000] Accuracy: 56.51%\n",
      "[9,000] Accuracy: 56.66%\n",
      "[10,000] Accuracy: 56.99%\n",
      "[11,000] Accuracy: 57.09%\n",
      "[12,000] Accuracy: 57.04%\n",
      "[13,000] Accuracy: 57.02%\n",
      "[14,000] Accuracy: 56.92%\n",
      "[15,000] Accuracy: 56.71%\n",
      "[16,000] Accuracy: 56.78%\n",
      "[17,000] Accuracy: 56.75%\n",
      "[18,000] Accuracy: 56.75%\n",
      "[19,000] Accuracy: 56.62%\n",
      "[20,000] Accuracy: 56.61%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 56.61%"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NoChangeClassifier()\n",
    "metric = Accuracy()\n",
    "stream = synth.SEA(seed=42).take(20000)\n",
    "\n",
    "progressive_val_score(dataset=stream, model=model, metric=metric, print_every=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
